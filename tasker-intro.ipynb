{
 "metadata": {
  "name": "",
  "signature": "sha256:fb87eb78f21881245f41c455131af9a7df081d320cd3c572f2a3bc9b8b71b4b6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Tasker\n",
      "\n",
      "Tasker is a Python package for organizing and processing scientific data. It is a framework for constructing your own organization scheme and processing code. Let's dive into an example:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Without Tasker\n",
      "\n",
      "We're going to do a trivial, multi-step computation, first as a simple script, and then with Tasker."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, let's set up a directory to hold our computation, and put a token data file in it."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!mkdir -p 'taskerdemo_dir'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file taskerdemo_dir/anumber.txt\n",
      "1.5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing taskerdemo_dir/anumber.txt\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import time\n",
      "import numpy as np\n",
      "import pandas"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scale = 10\n",
      "\n",
      "# Make some random data\n",
      "raw_random_nums = np.random.normal(size=(100,))\n",
      "random_nums = pandas.Series(raw_random_nums * scale)\n",
      "# Read the parameter we stored earlier\n",
      "shift = float(open('taskerdemo_dir/anumber.txt').read().strip())\n",
      "# Transform the data\n",
      "nums = random_nums + shift\n",
      "# Compute some statistics\n",
      "summary = {'mean': nums.mean(), 'std': nums.std(), 'count': nums.count()}\n",
      "std_err = summary['std'] / np.sqrt(summary['count'])\n",
      "summary['std_err'] = std_err\n",
      "# Write summary to a text file\n",
      "open('taskerdemo_dir/oldstats.txt', 'w').write(''.join(\n",
      "            ['%s: %.2g\\n' % (k, v) for k, v in summary.items()]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Great! That was easy. But there are a few drawbacks to this method:\n",
      "\n",
      "- Imagine that these computations actually take a long time. If we change something, or have to restart this Python session, we'll need to recompute everything, instead of reusing past results where possible.\n",
      "\n",
      "- This code works fine for \"mydir,\" but when it's time to run it on \"mydir2\", \"mydir3\", etc., there is extra work involved in managing it all.\n",
      "\n",
      "- We're sick of always waiting for the computation to finish, so we write code to save the results to disk. When we want to use these results in other notebooks or scripts, we write more code to load them there. When we want to revisit *this* notebook, we'll change it to load the past results instead of re-computing. And when we someday *do* need to re-compute, we'll write yet more code to switch this notebook between the two behaviors.\n",
      "\n",
      "# With Tasker\n",
      "\n",
      "Now, let's look at the same computation, written using some of the features of Tasker. Again, imagine each step in this computation being non-trivial and taking a long time."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import tasker\n",
      "\n",
      "# Make a Tasker instance for this directory.\n",
      "# Omit the argument if you just want to use the current directory.\n",
      "mydir = tasker.Tasker('taskerdemo_dir')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, let's set some parameters. *For convenience only*, each Tasker instance provides a `conf` attribute."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# You can set and get parameters as attributes...\n",
      "mydir.conf.scale = 10\n",
      "\n",
      "print mydir.conf.scale\n",
      "# Or, equivalently, use \"conf\" as a dictionary:\n",
      "print mydir.conf['scale']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10\n",
        "10\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's define some tasks. Tasker uses Python *decorators* (the things with the \"`@`\" sign) to turn ordinary functions into tasks within `mydir`. The `stores` decorator means that the values returned by the function will be stored to files for later reuse."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Store this result using Python's \"pickle\" module.\n",
      "@mydir.stores(tasker.Pickle('random_nums.pickle'))\n",
      "def raw_random(tsk):\n",
      "    \"\"\"Random numbers in normal distribution\"\"\"\n",
      "    return np.random.normal(size=(100,))\n",
      "\n",
      "# Store as an HDF5 file.\n",
      "@mydir.stores(tasker.Pandas('random.h5'))\n",
      "# The output of raw_random() is automatically read from random_nums.pickle and\n",
      "# passed to the function.\n",
      "def random(tsk, rawnums=mydir.raw_random):\n",
      "    \"\"\"Scaled Pandas series of random numbers\"\"\"\n",
      "    return pandas.Series(rawnums * mydir.conf.scale)\n",
      "\n",
      "# This task doesn't store anything, and is always re-computed.\n",
      "@mydir\n",
      "# You can name arbitrary files as inputs, and then read them yourself.\n",
      "# Note that we just give the name of anumber.txt --- it's implicit that \n",
      "# it will be in mydir.\n",
      "def random_shift(tsk, nums=mydir.random, shiftfile='anumber.txt'):\n",
      "    \"\"\"Random numbers with shifted mean\"\"\"\n",
      "    shift = float(open(shiftfile).read().strip())\n",
      "    return nums + shift\n",
      "\n",
      "# Store as a JSON file (faithfully stores basic Python data types, \n",
      "# but also human-readable.)\n",
      "@mydir.stores(tasker.JSON('summary.json'))\n",
      "def summary(tsk, nums=mydir.random_shift):\n",
      "    \"\"\"Descriptive statistics about the random numbers\"\"\"\n",
      "    return {'mean': nums.mean(), 'std': nums.std(), 'count': nums.count()}\n",
      "\n",
      "@mydir\n",
      "def std_err(tsk, summary=mydir.summary):\n",
      "    return summary['std'] / np.sqrt(summary['count'])\n",
      "\n",
      "# Multiple outputs are OK too!\n",
      "# You can name arbitrary files as outputs, and write them yourself.\n",
      "@mydir.stores(tasker.JSON('stats.json'), 'stats.txt')\n",
      "def report_everything(tsk, std_err=mydir.std_err, summary=mydir.summary):\n",
      "    \"\"\"Summary of everything we computed\"\"\"\n",
      "    summary['std_err'] = std_err\n",
      "    open('stats.txt', 'w').write(''.join(\n",
      "            ['%s: %.2g\\n' % (k, v) for k, v in summary.items()]))\n",
      "    return summary, None  # None is placeholder for stats.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Clear results of any previous computations.\n",
      "# Ordinarily, we would NOT want to do this.\n",
      "mydir.clear()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# List defined tasks\n",
      "mydir.menu()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tasks for /Users/nkeim/python-notebooks/taskerdemo_dir:\n",
        "Done? Name               Description                                            \n",
        "--------------------------------------------------------------------------------\n",
        "      raw_random         Random numbers in normal distribution                  \n",
        "      random             Scaled Pandas series of random numbers                 \n",
        "      random_shift       Random numbers with shifted mean                       \n",
        "      summary            Descriptive statistics about the random numbers        \n",
        "      std_err                                                                   \n",
        "      report_everything  Summary of everything we computed                      \n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Obtaining values from tasks\n",
      "\n",
      "These tasks have become attributes of our Tasker instance. To get the value(s) computed by a task, simply call it like a function:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mydir.std_err()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "1.0208596469324347"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mydir.menu()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tasks for /Users/nkeim/python-notebooks/taskerdemo_dir:\n",
        "Done? Name               Description                                            \n",
        "--------------------------------------------------------------------------------\n",
        "  +   raw_random         Random numbers in normal distribution                  \n",
        "  +   random             Scaled Pandas series of random numbers                 \n",
        "  +   random_shift       Random numbers with shifted mean                       \n",
        "  +   summary            Descriptive statistics about the random numbers        \n",
        "  +   std_err                                                                   \n",
        "      report_everything  Summary of everything we computed                      \n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Whoa! The \"`+`\" next to each task means that to compute `std_err`, Tasker computed everything it depends on. Those values are available too:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mydir.summary()\n",
      "print mydir.summary()['mean']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{u'std': 10.208596469324347, u'count': 100, u'mean': 3.4315143202916225}\n",
        "3.43151432029\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Stored values\n",
      "\n",
      "The files we specified earlier now contain the results. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!ls taskerdemo_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "anumber.txt        random.h5          summary.json\r\n",
        "oldstats.txt       random_nums.pickle\r\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Of course, the files contain the same data you get from the Tasker instance:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!cat taskerdemo_dir/summary.json"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "{\r\n",
        "    \"std\": 10.208596469324347,\r\n",
        "    \"count\": 100,\r\n",
        "    \"mean\": 3.4315143202916225\r\n",
        "}"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recall that `report_everything()` writes to both a JSON file (courtesy of Tasker) and to `stats.txt` in some non-standard format. When we ask for the value of `report_everything()`, we get the contents of the JSON file, but we're just told where the other one is:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mydir.report_everything()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "[{u'count': 100,\n",
        "  u'mean': 3.4315143202916225,\n",
        "  u'std': 10.208596469324347,\n",
        "  u'std_err': 1.0208596469324347},\n",
        " path(u'/Users/nkeim/python-notebooks/taskerdemo_dir/stats.txt')]"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Invalidating old results\n",
      "\n",
      "Let's change the contents of `anumber.txt`, and see what happens."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file taskerdemo_dir/anumber.txt\n",
      "-10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Overwriting taskerdemo_dir/anumber.txt\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mydir.menu()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tasks for /Users/nkeim/python-notebooks/taskerdemo_dir:\n",
        "Done? Name               Description                                            \n",
        "--------------------------------------------------------------------------------\n",
        "  +   raw_random         Random numbers in normal distribution                  \n",
        "  +   random             Scaled Pandas series of random numbers                 \n",
        "  +   random_shift       Random numbers with shifted mean                       \n",
        "      summary            Descriptive statistics about the random numbers        \n",
        "      std_err                                                                   \n",
        "      report_everything  Summary of everything we computed                      \n"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Look! The stored results that depended on `anumber.txt` \u2014 `summary`, `std_err`, and `report_everything` \u2014 are now invalid. They'll be re-computed the next time they are needed. (Since `random_shift` does not store its results, it was not invalidated.)\n",
      "\n",
      "Users of the `make` tool for compiling C code will be familiar with this behavior, which works by comparing the modification times on the input and output files."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Paths, working directories, and the task environment\n",
      "\n",
      "### `path.py` objects\n",
      "\n",
      "Tasker uses the excellent `path.py` module wherever possible. The \"`p`\" attribute of a `Tasker` instance will give you an object from `path.py`:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mydir.p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "path(u'/Users/nkeim/python-notebooks/taskerdemo_dir')"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mydir.p.glob('*.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "[path(u'/Users/nkeim/python-notebooks/taskerdemo_dir/anumber.txt'),\n",
        " path(u'/Users/nkeim/python-notebooks/taskerdemo_dir/oldstats.txt'),\n",
        " path(u'/Users/nkeim/python-notebooks/taskerdemo_dir/stats.txt')]"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mydir.p / 'testing'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 20,
       "text": [
        "path(u'/Users/nkeim/python-notebooks/taskerdemo_dir/testing')"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Working directory of tasks\n",
      "\n",
      "Tasks are always executed in the directory of the parent `Tasker` instance. In the definition of `report_everything()` reproduced here, notice how we write `open('stats.txt', 'w')`, not `open('mydir/stats.txt, 'w')`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@mydir.stores(tasker.JSON('stats.json'), 'stats.txt')\n",
      "def report_everything(tsk, std_err=mydir.std_err, summary=mydir.summary):\n",
      "    \"\"\"Summary of everything we computed\"\"\"\n",
      "    summary['std_err'] = std_err\n",
      "    open('stats.txt', 'w').write(''.join(\n",
      "            ['%s: %.2g\\n' % (k, v) for k, v in summary.items()]))\n",
      "    return summary, None  # None is placeholder for stats.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can borrow this directory-changing feature for your own purposes by using the `Tasker` instance as a context:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "\n",
      "print os.getcwd()\n",
      "with mydir:\n",
      "    print os.getcwd()\n",
      "print os.getcwd()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/nkeim/python-notebooks\n",
        "/Users/nkeim/python-notebooks/taskerdemo_dir\n",
        "/Users/nkeim/python-notebooks\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "All this can get a little confusing. Just remember that the \"`p`\" attribute of your `Tasker` instance is an *absolute* path (starts with \"`/`\", or \"`C:\\`\", or whatever), so it works the same everywhere."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print mydir.p.glob('*.txt')[0]\n",
      "with mydir:\n",
      "    print mydir.p.glob('*.txt')[0]  # Does exactly the same thing."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/Users/nkeim/python-notebooks/taskerdemo_dir/anumber.txt\n",
        "/Users/nkeim/python-notebooks/taskerdemo_dir/anumber.txt\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### The `tsk` argument\n",
      "\n",
      "The first argument to a task (conventionally called `tsk`) is the task object itself. One use for `tsk` is that its `output_files` attribute is a list of output files. This lets you get *all* your filenames from the header information at the top of the task. \n",
      "\n",
      "The `report_everything()` task can therefore be rewritten as"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "@mydir.stores(tasker.JSON('stats.json'), 'stats.txt')\n",
      "def report_everything(tsk, std_err=mydir.std_err, summary=mydir.summary):\n",
      "    \"\"\"Summary of everything we computed\"\"\"\n",
      "    summary['std_err'] = std_err\n",
      "    open(tsk.output_files[1], 'w').write(''.join(\n",
      "            ['%s: %.2g\\n' % (k, v) for k, v in summary.items()]))\n",
      "    return summary, None  # None is placeholder for stats.txt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## The user interface\n",
      "\n",
      "Useful methods of a task (e.g. `mydir.summary`) include\n",
      "\n",
      "- `clear()`: Delete the task's output files.\n",
      "- `force()`: Delete the output files and return the re-computed value.\n",
      "- `is_current()`: True if nothing needs to be re-computed.\n",
      "- `report()`: Return this task, and any task it depends on, that need to be re-computed.\n",
      "\n",
      "Useful methods of the Tasker instance (e.g. `mydir`) include\n",
      "\n",
      "- `clear()`: Delete output files of all defined tasks.\n",
      "- `menu()`: See above.\n",
      "- `which(filename)`: Find out which task(s) create the output file `filename`.\n",
      "- `unlock()`: Re-enable tasks after a hard crash. (See the section on locking, below.)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Taskfiles\n",
      "\n",
      "It would be nice to let multiple notebooks, scripts, etc. use a common set of task definitions. Using any text editor, you can create a `taskfile.py` file in your data directory. For example:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%file taskerdemo_dir/taskfile.py\n",
      "\n",
      "import tasker\n",
      "\n",
      "def use(dirname):\n",
      "    mydir = tasker.Tasker(dirname)  # Create the Tasker instance\n",
      "    \n",
      "    mydir.conf.scale = 10  # Configure it\n",
      "    \n",
      "    # Create 2 example tasks (cribbed from above):\n",
      "    \n",
      "    # Store this result using Python's \"pickle\" module.\n",
      "    @mydir.stores(tasker.Pickle('random_nums.pickle'))\n",
      "    def raw_random(tsk):\n",
      "        \"\"\"Random numbers in normal distribution\"\"\"\n",
      "        return np.random.normal(size=(100,))\n",
      "\n",
      "    # Store as an HDF5 file.\n",
      "    @mydir.stores(tasker.Pandas('random.h5'))\n",
      "    # The output of raw_random() is automatically read from random_nums.pickle and\n",
      "    # passed to the function.\n",
      "    def random(tsk, rawnums=mydir.raw_random):\n",
      "        \"\"\"Scaled Pandas series of random numbers\"\"\"\n",
      "        return pandas.Series(rawnums * mydir.conf.scale)\n",
      "    \n",
      "    return mydir  # Very important!"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Writing taskerdemo_dir/taskfile.py\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, whenever you call\n",
      "\n",
      "```\n",
      "tasker.use('mydir')\n",
      "```\n",
      "\n",
      "Tasker looks for `taskfile.py` in `mydir`, finds the `use()` function defined within it, and calls it with the path to the directory:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mydir_fromfile = tasker.use('taskerdemo_dir')\n",
      "mydir_fromfile.menu()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Tasks for /Users/nkeim/python-notebooks/taskerdemo_dir:\n",
        "Done? Name        Description                                                   \n",
        "--------------------------------------------------------------------------------\n",
        "  +   raw_random  Random numbers in normal distribution                         \n",
        "  +   random      Scaled Pandas series of random numbers                        \n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Subdirectory taskfiles\n",
      "\n",
      "Often you will have a bunch of subdirectories, each containing a single movie or the results of a single experiment, that all need to be processed in a similar way. Rather than putting an identical `taskfile.py` in each directory, you can place a single `taskfile_sub.py` in the parent directory, and `tasker.use()` will find it.\n",
      "\n",
      "In a situation like this, you may want to *also* put a `taskfile.py` in the parent directory, to help you manage and organize all the subdirectories. Tasker includes a special `SetTasker` class to get you started."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# `Tasker` objects are Python objects\n",
      "\n",
      "Lastly, as you're writing and editing your taskfile, remember that you can judiciously add lots of other goodies to your `Tasker` instances. For example, \n",
      "\n",
      "- Let's say the name of the directory contains some useful metadata (like the value of a parameter). Then your `use()` function could parse that name (available as `mydir.name`) and give the object a new attribute (e.g. `mydir.voltage`).\n",
      "- Tasker's storage objects can stand alone, unattached to a task. For example,"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mydir.params = tasker.JSON(mydir.p / 'params.json')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "lets you do"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mydir.params.save({'voltage': 3.4, 'objective': '10x', 'good': True})\n",
      "mydir.params()  # Read from disk"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "{u'good': True, u'objective': u'10x', u'voltage': 3.4}"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Subclassing\n",
      "\n",
      "For ultimate flexibility, you can subclass `Tasker` as you would any other Python class. Then you can customize `__init__()`, or add properties and methods that are not tasks at all. For example, you may already have a function that takes lots of arguments, some of which you'd like to specify, but most of which depend on the experiment you happen to be analyzing. By defining a method, you can make all of the latter parameters implicit, *potentially* improving the readability of your notebooks, etc."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Parallel Computation\n",
      "\n",
      "When you have many similar directories to process (see the bit about subdirectory taskfiles above), Tasker is beautifully suited to processing them in parallel. It's beyond the scope of this tutorial, but actually not that hard \u2014 each parallel \"job\" for a worker consists of something like\n",
      "\n",
      "```\n",
      "import sys, tasker\n",
      "dirpath = sys.argv[1]  # ...or however you tell workers where to work\n",
      "t = tasker.use(dirpath)\n",
      "t.the_task_I_want()\n",
      "```\n",
      "\n",
      "The results of `the_task_I_want` will be stored on disk and ready for you to use later. Because you're using Tasker, if something goes wrong with your massive parallel computation, only the parts that failed will have to be re-run.\n",
      "\n",
      "That said, a proper tutorial on this feature is missing. Especially important are Tasker's facilities for monitoring the progress of your jobs, including estimated time to completion.\n",
      "\n",
      "## An important detail: Locking\n",
      "\n",
      "To preserve a modicum of sanity in this world (especially when parallel computing is involved), no two Tasker instances can ever run the same task in the same directory at the same time. A lock file is created when a task is started, and deleted when it finishes (or aborts). The downside is that a catastrophe like a hard crash or sudden power loss can leave the lock in place. To recover, use the `unlock()` method of a Tasker instance."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Learning more\n",
      "\n",
      "With the exception of parallel computing, we've basically covered everything. Tasker was designed to be minimal. But of course there are details, and for those, the docstrings, the source code, and the author are all helpful."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    }
   ],
   "metadata": {}
  }
 ]
}